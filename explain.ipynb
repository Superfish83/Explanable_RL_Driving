{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.10.0)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyjun\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from Network_PER import *\n",
    "from DriveSimTrace import *\n",
    "import shap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP, Decomposed Reward 정보를 통한 설명 텍스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_explain(pred_list):\n",
    "    pred_label = [\"reach finish line\", \"avoid the obstacle\", \"avoid the wall\"]\n",
    "    action_label = [\"Idle\", \"Accel\", \"Decel\", \"Turn Left\", \"Turn Right\"]\n",
    "\n",
    "    pred_sum = np.sum(pred_list, axis=0)\n",
    "    chosen = np.argmax(pred_sum)\n",
    "    compare = np.argmin(pred_sum)\n",
    "\n",
    "    diff = np.transpose(pred_list)[chosen] - np.transpose(pred_list)[compare]\n",
    "    diff = diff[0]\n",
    "\n",
    "    txt = [f\"I chose '{action_label[chosen]}' rather than '{action_label[compare]}' because it seemed more likely to help me \",\"\"]\n",
    "    \n",
    "    for i in range(np.size(diff)):\n",
    "        if diff[i] > 0:\n",
    "            txt[1] += f\"{pred_label[i]}(+{ str(round(diff[i], 2)) })/\"\n",
    "    \n",
    "    txt[1] = txt[1][:-1] + \".\"\n",
    "\n",
    "    return txt\n",
    "\n",
    "def shap_explain(shap_list):\n",
    "    state_label = [\"Speed\",\"Rotation\",\"Agent X Position\",\"Agent Y Position\",\\\n",
    "        \"Obstacle X Position\",\"Obstacle Y Position\",\"Obstacle Size\"]\n",
    "\n",
    "    shap_list = shap_list[0]\n",
    "    imp1 = np.argmax(shap_list)\n",
    "    imp1val = shap_list[imp1]\n",
    "    shap_list[imp1] = -100000\n",
    "\n",
    "    imp2 = np.argmax(shap_list)\n",
    "    imp2val = shap_list[imp2]\n",
    "\n",
    "    txt = [f\"I considered '{state_label[imp1]}'({ str(round(imp1val, 6)) }) and '{state_label[imp2]}'({ str(round(imp2val, 6)) })\",\\\n",
    "     f\"the most important in making this decision.\"]\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시뮬레이션 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Prioritized Sampling: False\n",
      "loaded weights from ./models/q_20230226(0)\n",
      "0\n",
      "1\n",
      "[array([[ 0.        ,  0.        ,  0.        ,  0.        , -0.00727652,\n",
      "        -0.00224786, -0.01352898]]), array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00, -1.10040195e-02, -8.66591930e-05,\n",
      "        -2.05415799e-02]]), array([[ 0.        ,  0.        ,  0.        ,  0.        , -0.01065472,\n",
      "        -0.00096306, -0.01763316]]), array([[ 0.        ,  0.        ,  0.        ,  0.        , -0.01048209,\n",
      "         0.00723628, -0.01585459]]), array([[ 0.        ,  0.        ,  0.        ,  0.        , -0.00449371,\n",
      "        -0.00822055, -0.01513968]])]\n",
      "[[ 0.          0.          0.          0.         -0.04391106 -0.00428184\n",
      "  -0.08269799]]\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -7.27651771e-03 -2.24785618e-03 -1.35289781e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -1.10040195e-02 -8.66591930e-05 -2.05415799e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -1.06547157e-02 -9.63055342e-04 -1.76331607e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -1.04820935e-02  7.23628029e-03 -1.58545853e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -4.49371044e-03 -8.22054744e-03 -1.51396850e-02]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    import silence_tensorflow\n",
    "    silence_tensorflow.silence_tensorflow()\n",
    "\n",
    "    #시뮬레이션 테스트 코드\n",
    "    n_runs = 1000\n",
    "    for k in range(1):\n",
    "        model_path = f'./models/q_20230226(0)'\n",
    "\n",
    "        #train_scores_1 = np.genfromtxt('20221003_concat_train_scores_1.csv', delimiter=',')\n",
    "\n",
    "        wins = 0\n",
    "        agent = Agent(lr=0, gamma=0.99, n_actions=5, batch_size=64, epsilon=0.0, input_dims=[1, 7], per_on=False)\n",
    "\n",
    "        agent.load_model(model_path)\n",
    "\n",
    "        sim = DriveSimulator()\n",
    "        avg_score = 0.0\n",
    "\n",
    "\n",
    "        collect_bg = 1\n",
    "        background = []\n",
    "\n",
    "        for i in range(n_runs):\n",
    "            over = False\n",
    "            sim.reset(frame_rate=3000)\n",
    "            state = sim.get_sim_state()\n",
    "\n",
    "            print(i)\n",
    "            if i >= collect_bg:\n",
    "                sim.explain = True\n",
    "                bg = (np.array(background))\n",
    "                e_0 = shap.DeepExplainer(agent.q_evals[0], bg[0] )\n",
    "                e_1 = shap.DeepExplainer(agent.q_evals[1], bg[0] )\n",
    "                e_2 = shap.DeepExplainer(agent.q_evals[2], bg[0] )\n",
    "\n",
    "            while not over:\n",
    "\n",
    "                if sim.explain:\n",
    "                    for event in pygame.event.get():\n",
    "                        if event.type == pygame.KEYDOWN: #and event.key == pygame.K_SPACE: # 스페이스 키 입력 시에만 프레임 넘김\n",
    "                            \n",
    "                            #SHAP Explainer -> 현재 state에서 가장 중요한 정보 찾기\n",
    "                            shap_values = (e_0.shap_values( state ))\n",
    "                            print(shap_values)\n",
    "                            print(np.sum(shap_values, axis=0))\n",
    "                            print(np.sum(shap_values, axis=1))\n",
    "                            shap_values += (e_1.shap_values( state ))\n",
    "                            shap_values += (e_2.shap_values( state ))\n",
    "\n",
    "                            #시뮬레이션 업데이트\n",
    "                            action, pred, pred_C = agent.choose_action(state)\n",
    "                            state_, stpRwd, sim_over = sim.step(action, pred_C)\n",
    "                            over = sim_over\n",
    "                            state = state_\n",
    "\n",
    "\n",
    "                            #설명(SHAP+Reward Decomposition) 화면에 표시\n",
    "                            sim.render_explanation(shap_values, pred_C, \\\n",
    "                                 shap_explain(shap_values[action]), pred_explain(pred_C))\n",
    "\n",
    "                else:\n",
    "                    background.append(np.array(state))\n",
    "                \n",
    "                    action, pred, pred_C = agent.choose_action(state)\n",
    "                    state_, stpRwd, sim_over = sim.step(action, pred_C)\n",
    "                    over = sim_over\n",
    "                    state = state_\n",
    "                 \n",
    "            avg_score += sim.agtRwd\n",
    "            if sim.agtRwd[0] > 0:\n",
    "                wins+=1\n",
    "\n",
    "        print(wins)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2ca063fdbe114e1b6e4d04529a071bcb4f5c073e5b3f4bc04898c7d4aae4031"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
