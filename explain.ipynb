{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.10.0)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyjun\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from Network_PER import *\n",
    "from DriveSimTrace import *\n",
    "import shap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP, Decomposed Reward 정보를 통한 설명 텍스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_explain(pred_list):\n",
    "    pred_label = [\"reach finish line\", \"avoid the obstacle\", \"avoid the wall\"]\n",
    "    action_label = [\"Idle\", \"Accel\", \"Decel\", \"Turn Left\", \"Turn Right\"]\n",
    "\n",
    "    pred_sum = np.sum(pred_list, axis=0)\n",
    "    chosen = np.argmax(pred_sum)\n",
    "    compare = np.argmin(pred_sum)\n",
    "\n",
    "    diff = np.transpose(pred_list)[chosen] - np.transpose(pred_list)[compare]\n",
    "    diff = diff[0]\n",
    "\n",
    "    txt = [f\"I chose '{action_label[chosen]}' rather than '{action_label[compare]}' because it seemed more likely to help me \",\"\"]\n",
    "    \n",
    "    for i in range(np.size(diff)):\n",
    "        if diff[i] > 0:\n",
    "            txt[1] += f\"{pred_label[i]}(+{ str(round(diff[i], 2)) })/\"\n",
    "    \n",
    "    txt[1] = txt[1][:-1] + \".\"\n",
    "\n",
    "    return txt\n",
    "\n",
    "def shap_explain(shap_list):\n",
    "    state_label = [\"Speed\",\"Rotation\",\"Agent X Position\",\"Agent Y Position\",\\\n",
    "        \"Obstacle X Position\",\"Obstacle Y Position\",\"Obstacle Size\"]\n",
    "\n",
    "    shap_list = shap_list[0,0]\n",
    "    imp1 = np.argmax(shap_list)\n",
    "    imp1val = shap_list[imp1]\n",
    "    shap_list[imp1] = -100000\n",
    "\n",
    "    imp2 = np.argmax(shap_list)\n",
    "    imp2val = shap_list[imp2]\n",
    "\n",
    "    txt = [f\"I considered '{state_label[imp1]}'({ str(round(imp1val, 3)) }) and '{state_label[imp2]}'({ str(round(imp2val, 3)) })\",\\\n",
    "     f\"the most important in making this decision.\"]\n",
    "    return txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시뮬레이션 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Prioritized Sampling: False\n",
      "loaded weights from ./models/q_20230226(0)\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Event' object has no attribute 'key'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mif\u001b[39;00m sim\u001b[39m.\u001b[39mexplain:\n\u001b[0;32m     40\u001b[0m     \u001b[39mfor\u001b[39;00m event \u001b[39min\u001b[39;00m pygame\u001b[39m.\u001b[39mevent\u001b[39m.\u001b[39mget():\n\u001b[1;32m---> 41\u001b[0m         \u001b[39mif\u001b[39;00m event\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m pygame\u001b[39m.\u001b[39mKEYDOWN \u001b[39mor\u001b[39;00m event\u001b[39m.\u001b[39;49mkey \u001b[39m==\u001b[39m pygame\u001b[39m.\u001b[39mK_SPACE: \u001b[39m# 스페이스 키 입력 시에만 프레임 넘김\u001b[39;00m\n\u001b[0;32m     42\u001b[0m             \n\u001b[0;32m     43\u001b[0m             \u001b[39m#SHAP Explainer -> 현재 state에서 가장 중요한 정보 찾기\u001b[39;00m\n\u001b[0;32m     44\u001b[0m             shap_values \u001b[39m=\u001b[39m (e_0\u001b[39m.\u001b[39mshap_values( np\u001b[39m.\u001b[39marray([state]) ))\n\u001b[0;32m     45\u001b[0m             shap_values \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (e_1\u001b[39m.\u001b[39mshap_values( np\u001b[39m.\u001b[39marray([state]) ))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Event' object has no attribute 'key'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    import silence_tensorflow\n",
    "    silence_tensorflow.silence_tensorflow()\n",
    "\n",
    "    #시뮬레이션 테스트 코드\n",
    "    n_runs = 1000\n",
    "    for k in range(1):\n",
    "        model_path = f'./models/q_20230226(0)'\n",
    "\n",
    "        #train_scores_1 = np.genfromtxt('20221003_concat_train_scores_1.csv', delimiter=',')\n",
    "\n",
    "        wins = 0\n",
    "        agent = Agent(lr=0, gamma=0.99, n_actions=5, batch_size=64, epsilon=0.0, input_dims=[1, 7], per_on=False)\n",
    "\n",
    "        agent.load_model(model_path)\n",
    "\n",
    "        sim = DriveSimulator()\n",
    "        avg_score = 0.0\n",
    "\n",
    "\n",
    "        collect_bg = 1\n",
    "        background = []\n",
    "\n",
    "        for i in range(n_runs):\n",
    "            over = False\n",
    "            sim.reset(frame_rate=3000)\n",
    "            state = sim.get_sim_state()\n",
    "\n",
    "            print(i)\n",
    "            if i >= collect_bg:\n",
    "                sim.explain = True\n",
    "                bg = (np.array(background))\n",
    "                e_0 = shap.DeepExplainer(agent.q_evals[0], np.array([bg[0]]) )\n",
    "                e_1 = shap.DeepExplainer(agent.q_evals[1], np.array([bg[0]]) )\n",
    "                e_2 = shap.DeepExplainer(agent.q_evals[2], np.array([bg[0]]) )\n",
    "\n",
    "            while not over:\n",
    "\n",
    "                if sim.explain:\n",
    "                    for event in pygame.event.get():\n",
    "                        if event.type == pygame.KEYDOWN: #and event.key == pygame.K_SPACE: # 스페이스 키 입력 시에만 프레임 넘김\n",
    "                            \n",
    "                            #SHAP Explainer -> 현재 state에서 가장 중요한 정보 찾기\n",
    "                            shap_values = (e_0.shap_values( np.array([state]) ))\n",
    "                            shap_values += (e_1.shap_values( np.array([state]) ))\n",
    "                            shap_values += (e_2.shap_values( np.array([state]) ))\n",
    "\n",
    "                            #시뮬레이션 업데이트\n",
    "                            action, pred, pred_C = agent.choose_action(state)\n",
    "                            state_, stpRwd, sim_over = sim.step(action, pred_C)\n",
    "                            over = sim_over\n",
    "                            state = state_\n",
    "\n",
    "\n",
    "                            #설명(SHAP+Reward Decomposition) 화면에 표시\n",
    "                            sim.render_explanation(shap_values, pred_C, \\\n",
    "                                 shap_explain(shap_values[action]), pred_explain(pred_C))\n",
    "\n",
    "                else:\n",
    "                    background.append(np.array(state))\n",
    "                \n",
    "                    action, pred, pred_C = agent.choose_action(state)\n",
    "                    state_, stpRwd, sim_over = sim.step(action, pred_C)\n",
    "                    over = sim_over\n",
    "                    state = state_\n",
    "                 \n",
    "            avg_score += sim.agtRwd\n",
    "            if sim.agtRwd[0] > 0:\n",
    "                wins+=1\n",
    "\n",
    "        print(wins)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2ca063fdbe114e1b6e4d04529a071bcb4f5c073e5b3f4bc04898c7d4aae4031"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
