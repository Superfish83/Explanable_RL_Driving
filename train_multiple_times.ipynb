{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.10.0)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from Network_PER import *\n",
    "from DriveSimTrace import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.002\n",
      "Use Prioritized Sampling: True\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 100 , average score(last 100 episodes): -2.363 average loss: 0.3826993931434117 wins: 20 eps: 0.99\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 200 , average score(last 100 episodes): -2.8915999999999986 average loss: 0.15256942368985618 wins: 37 eps: 0.98\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 300 , average score(last 100 episodes): -3.1354999999999986 average loss: 0.13798347044008552 wins: 52 eps: 0.97\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 400 , average score(last 100 episodes): -1.5734000000000001 average loss: 0.14863568163476884 wins: 78 eps: 0.96\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 500 , average score(last 100 episodes): -2.8568000000000007 average loss: 0.21232650612364523 wins: 98 eps: 0.95\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 600 , average score(last 100 episodes): -2.605100000000001 average loss: 0.3298101948240946 wins: 117 eps: 0.94\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 700 , average score(last 100 episodes): -3.473899999999998 average loss: 0.2948206115308858 wins: 131 eps: 0.93\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 800 , average score(last 100 episodes): -2.9636 average loss: 0.2390139419508341 wins: 149 eps: 0.92\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 900 , average score(last 100 episodes): -2.6903 average loss: 0.2362892021301377 wins: 169 eps: 0.91\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 1000 , average score(last 100 episodes): -4.004299999999998 average loss: 0.27786335693497677 wins: 181 eps: 0.9\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 1100 , average score(last 100 episodes): -4.1419999999999995 average loss: 0.3604234950398677 wins: 190 eps: 0.89\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 1200 , average score(last 100 episodes): -2.3543000000000007 average loss: 0.33061826317556553 wins: 210 eps: 0.88\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 1300 , average score(last 100 episodes): -3.663799999999999 average loss: 0.4500672646050225 wins: 225 eps: 0.87\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 1400 , average score(last 100 episodes): -4.2928999999999995 average loss: 0.39307699480224984 wins: 239 eps: 0.86\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 1500 , average score(last 100 episodes): -3.0548000000000015 average loss: 0.3527877952058043 wins: 257 eps: 0.85\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 1600 , average score(last 100 episodes): -3.5536999999999996 average loss: 0.44145099274639504 wins: 271 eps: 0.84\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 1700 , average score(last 100 episodes): -2.9426 average loss: 0.5007826311571989 wins: 287 eps: 0.83\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 1800 , average score(last 100 episodes): -3.323000000000001 average loss: 0.5145275782534736 wins: 303 eps: 0.82\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 1900 , average score(last 100 episodes): -2.8615999999999984 average loss: 0.4581165872787824 wins: 324 eps: 0.81\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 2000 , average score(last 100 episodes): -3.425899999999998 average loss: 0.31222526203724554 wins: 345 eps: 0.8\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 2100 , average score(last 100 episodes): -4.110799999999995 average loss: 0.33550419385486746 wins: 363 eps: 0.79\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 2200 , average score(last 100 episodes): -4.194699999999998 average loss: 0.4099036052802694 wins: 381 eps: 0.78\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 2300 , average score(last 100 episodes): -5.181199999999997 average loss: 0.3434514293756365 wins: 402 eps: 0.77\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 2400 , average score(last 100 episodes): -7.2019 average loss: 0.34095720369361515 wins: 409 eps: 0.76\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 2500 , average score(last 100 episodes): -8.894499999999995 average loss: 0.21686788659644662 wins: 418 eps: 0.75\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 2600 , average score(last 100 episodes): -8.077799999999995 average loss: 0.3064182991690177 wins: 426 eps: 0.74\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 2700 , average score(last 100 episodes): -8.183699999999991 average loss: 0.2864943834752194 wins: 436 eps: 0.73\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 2800 , average score(last 100 episodes): -9.323899999999991 average loss: 0.24000296936676022 wins: 442 eps: 0.72\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 2900 , average score(last 100 episodes): -9.52949999999999 average loss: 0.21271319035120542 wins: 449 eps: 0.71\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 3000 , average score(last 100 episodes): -9.264399999999984 average loss: 0.2606965445396054 wins: 458 eps: 0.7\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 3100 , average score(last 100 episodes): -10.021999999999998 average loss: 0.20159493737235606 wins: 468 eps: 0.69\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 3200 , average score(last 100 episodes): -11.065899999999983 average loss: 0.2097532974709611 wins: 477 eps: 0.68\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 3300 , average score(last 100 episodes): -11.455099999999995 average loss: 0.24356567805731175 wins: 485 eps: 0.67\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 3400 , average score(last 100 episodes): -10.44299999999999 average loss: 0.18602504267168116 wins: 500 eps: 0.66\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 3500 , average score(last 100 episodes): -11.942499999999981 average loss: 0.21457842456416984 wins: 510 eps: 0.65\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 3600 , average score(last 100 episodes): -13.178899999999981 average loss: 0.14712132967782965 wins: 515 eps: 0.64\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 3700 , average score(last 100 episodes): -11.74649999999998 average loss: 0.14502588643656053 wins: 527 eps: 0.63\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 3800 , average score(last 100 episodes): -13.643199999999995 average loss: 0.14716094595743925 wins: 532 eps: 0.62\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 3900 , average score(last 100 episodes): -15.484799999999991 average loss: 0.16066097140093916 wins: 537 eps: 0.61\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 4000 , average score(last 100 episodes): -15.485299999999985 average loss: 0.14371401838383463 wins: 540 eps: 0.6\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 4100 , average score(last 100 episodes): -15.44029999999999 average loss: 0.16510855869710211 wins: 546 eps: 0.59\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 4200 , average score(last 100 episodes): -13.377999999999984 average loss: 0.22578818825058988 wins: 553 eps: 0.58\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 4300 , average score(last 100 episodes): -12.829399999999978 average loss: 0.17454547076085875 wins: 565 eps: 0.57\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 4400 , average score(last 100 episodes): -14.236099999999999 average loss: 0.13004701341087638 wins: 575 eps: 0.56\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 4500 , average score(last 100 episodes): -14.431099999999988 average loss: 0.17878764135377423 wins: 589 eps: 0.55\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 4600 , average score(last 100 episodes): -14.105199999999984 average loss: 0.17790293418864167 wins: 596 eps: 0.54\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 4700 , average score(last 100 episodes): -14.605299999999982 average loss: 0.1969976980724823 wins: 603 eps: 0.53\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 4800 , average score(last 100 episodes): -15.48839999999998 average loss: 0.14402636381099002 wins: 607 eps: 0.52\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 4900 , average score(last 100 episodes): -17.015500000000017 average loss: 0.1925519225937751 wins: 619 eps: 0.51\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 5000 , average score(last 100 episodes): -17.332600000000017 average loss: 0.13251715168313238 wins: 625 eps: 0.5\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 5100 , average score(last 100 episodes): -18.62800000000004 average loss: 0.11109112259367976 wins: 630 eps: 0.49\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 5200 , average score(last 100 episodes): -20.20920000000004 average loss: 0.1250648875645311 wins: 631 eps: 0.48\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 5300 , average score(last 100 episodes): -19.759500000000024 average loss: 0.14053854510075325 wins: 635 eps: 0.47\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 5400 , average score(last 100 episodes): -19.10030000000003 average loss: 0.148567452637526 wins: 639 eps: 0.46\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 5500 , average score(last 100 episodes): -18.612500000000026 average loss: 0.1072294112478994 wins: 643 eps: 0.45\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 5600 , average score(last 100 episodes): -19.733500000000024 average loss: 0.11410813700858853 wins: 645 eps: 0.44\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 5700 , average score(last 100 episodes): -16.04300000000001 average loss: 0.135507680989831 wins: 654 eps: 0.43\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 5800 , average score(last 100 episodes): -19.783500000000057 average loss: 0.1370787636104251 wins: 656 eps: 0.42\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 5900 , average score(last 100 episodes): -18.44040000000004 average loss: 0.1324089877860024 wins: 659 eps: 0.41\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 6000 , average score(last 100 episodes): -17.19080000000002 average loss: 0.09120797503179347 wins: 664 eps: 0.4\n",
      "q_next weight set!\n",
      "q_next weight set!\n",
      "Episode 6100 , average score(last 100 episodes): -18.835600000000046 average loss: 0.11780210732428714 wins: 666 eps: 0.39\n",
      "q_next weight set!\n",
      "q_next weight set!\n"
     ]
    }
   ],
   "source": [
    "#시뮬레이션 학습 코드\n",
    "EXP_COUNT = 1\n",
    "n_runs = 10000\n",
    "rwd_components = 3\n",
    "train_scores = np.zeros([EXP_COUNT,n_runs//100])\n",
    "train_losses = np.zeros([EXP_COUNT,n_runs//100])\n",
    "\n",
    "for exps in range(EXP_COUNT):\n",
    "    wins = 0\n",
    "    per = True\n",
    "    lrate = 0.001\n",
    "    print(\"learning rate:\", lrate)\n",
    "    agent = Agent(lr=lrate, gamma=0.99, n_actions=5, batch_size=64, epsilon=1.0, input_dims=[1,7], per_on=per)\n",
    "\n",
    "    sim = DriveSimulator()\n",
    "    epsilons = []\n",
    "    avg_score = 0.0\n",
    "    avg_loss = 0.0\n",
    "    \n",
    "    for i in range(n_runs):\n",
    "        over = False\n",
    "        sim.reset(frame_rate=3000)\n",
    "\n",
    "        state = sim.get_sim_state()\n",
    "        while not over:\n",
    "            action, pred, pred_C = agent.choose_action(state)\n",
    "            #print(action, pred)\n",
    "            state_, stpRwd, sim_over = sim.step(action, pred_C)\n",
    "            over = sim_over\n",
    "            \n",
    "            agent.store_transition(state, action, stpRwd, state_, over, pred)\n",
    "            state = state_\n",
    "        \n",
    "        Loss = agent.learn(exps)\n",
    "        #overestimation detection\n",
    "\n",
    "\n",
    "        agent.epsilon = round((1.0 - (float(i)/float(n_runs))),3)\n",
    "        #scores.append(sim.agtRwd)\n",
    "    \n",
    "        avg_score += np.sum(sim.agtRwd)\n",
    "        avg_loss += np.sum(Loss)\n",
    "        if sim.episode_count % 100 == 0:\n",
    "            avg_score /= 100\n",
    "            avg_loss /= 100\n",
    "            print('Episode', sim.episode_count, ', average score(last 100 episodes):', avg_score, \\\n",
    "                'average loss:', avg_loss, 'wins:', sim.win_count, 'eps:', agent.epsilon)\n",
    "\n",
    "            train_scores[exps, i//100] = avg_score\n",
    "            train_losses[exps, i//100] = avg_loss\n",
    "            avg_score = 0.0\n",
    "            avg_loss = 0.0\n",
    "            epsilons.append(agent.epsilon)\n",
    "\n",
    "    agent.save_model(f'./models/q_20230217({exps})')\n",
    "np.savetxt(f'20220217_scores.csv', train_scores, delimiter=\",\")\n",
    "np.savetxt(f'20220217_losses.csv', train_losses, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#시뮬레이션 학습 코드 (추가 학습)\n",
    "EXP_COUNT = 1\n",
    "n_runs = 10000\n",
    "rwd_components = 4\n",
    "train_scores = np.zeros([EXP_COUNT,n_runs//100])\n",
    "train_losses = np.zeros([EXP_COUNT,n_runs//100])\n",
    "\n",
    "for exps in range(EXP_COUNT):\n",
    "    wins = 0\n",
    "    per = True\n",
    "    lrate = 0.0005\n",
    "    print(\"learning rate:\", lrate)\n",
    "    agent = Agent(lr=lrate, gamma=0.999, n_actions=5, batch_size=64, epsilon=1.0, input_dims=[4,5], per_on=per)\n",
    "    \n",
    "    model = f'./models/q_20230214(0)'\n",
    "    agent.load_model(model)\n",
    "\n",
    "    sim = DriveSimulator()\n",
    "    epsilons = []\n",
    "    avg_score = 0.0\n",
    "    avg_loss = 0.0\n",
    "    \n",
    "    for i in range(n_runs):\n",
    "        over = False\n",
    "        sim.reset(frame_rate=3000)\n",
    "\n",
    "        state = sim.get_sim_state()\n",
    "        while not over:\n",
    "            action, pred, pred_C = agent.choose_action(state)\n",
    "            #print(action, pred)\n",
    "            state_, stpRwd, sim_over = sim.step(action, pred_C)\n",
    "            over = sim_over\n",
    "            \n",
    "            agent.store_transition(state, action, stpRwd, state_, over, pred)\n",
    "            state = state_\n",
    "        \n",
    "        Loss = agent.learn(exps)\n",
    "        #overestimation detection\n",
    "\n",
    "\n",
    "        agent.epsilon = round((1.0 - (float(i)/float(n_runs))),3)\n",
    "        #scores.append(sim.agtRwd)\n",
    "    \n",
    "        avg_score += np.sum(sim.agtRwd)\n",
    "        avg_loss += np.sum(Loss)\n",
    "        if sim.episode_count % 100 == 0:\n",
    "            avg_score /= 100\n",
    "            avg_loss /= 100\n",
    "            print('Episode', sim.episode_count, ', average score(last 100 episodes):', avg_score, \\\n",
    "                'average loss:', avg_loss, 'wins:', sim.win_count, 'eps:', agent.epsilon)\n",
    "\n",
    "            train_scores[exps, i//100] = avg_score\n",
    "            train_losses[exps, i//100] = avg_loss\n",
    "            avg_score = 0.0\n",
    "            avg_loss = 0.0\n",
    "            epsilons.append(agent.epsilon)\n",
    "\n",
    "    agent.save_model(f'./models/q_20230216({exps})')\n",
    "np.savetxt(f'20220216_scores.csv', train_scores, delimiter=\",\")\n",
    "np.savetxt(f'20220216_losses.csv', train_losses, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_graph(date, label):\n",
    "    scores = np.genfromtxt(date + '_scores.csv', delimiter=',')\n",
    "    losses = np.genfromtxt(date + '_losses.csv', delimiter=',')\n",
    "\n",
    "    # Plot Score\n",
    "    plt.title(label + ' (score)')\n",
    "    for i in range(EXP_COUNT):\n",
    "        plt.plot(scores[i], 'b')\n",
    "        plt.plot(8.0 * np.ones_like(scores[i]), 'gray') #Score 상한선\n",
    "        plt.plot(-5.0 * np.ones_like(scores[i]), 'gray') #Score 하한선\n",
    "        plt.show()\n",
    "    #plt.savefig(date + '_score.png')\n",
    "    #plt.show()\n",
    "\n",
    "    for i in range(EXP_COUNT):\n",
    "        plt.title(label + ' (loss)')\n",
    "        #Plot Loss\n",
    "        plt.plot(losses[i], 'orange')\n",
    "        plt.plot(1.5 * np.ones_like(losses[i]), 'gray') #Loss 상한선\n",
    "        plt.plot(np.zeros_like(losses[i]), 'gray') #Loss 하한선\n",
    "        plt.show()\n",
    "    #plt.savefig(date + '_loss.png')\n",
    "    #plt.show()\n",
    "\n",
    "save_graph(date = '20221209', label = 'test1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "f2ca063fdbe114e1b6e4d04529a071bcb4f5c073e5b3f4bc04898c7d4aae4031"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
