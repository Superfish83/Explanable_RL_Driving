{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Network_PER import *\n",
    "from DriveSim import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#시뮬레이션 학습 코드\n",
    "EXP_COUNT = 6\n",
    "n_runs = 10000\n",
    "train_scores = np.zeros([EXP_COUNT,n_runs//100])\n",
    "train_losses = np.zeros([EXP_COUNT,n_runs//100])\n",
    "\n",
    "for exps in range(EXP_COUNT):\n",
    "    wins = 0\n",
    "    per = False\n",
    "    if exps < 3:\n",
    "        per = True\n",
    "    lrate = 0.001\n",
    "    print(\"learning rate:\", lrate)\n",
    "    agent = Agent(lr=lrate, gamma=0.999, n_actions=5, batch_size=64, epsilon=1.0, input_dims=[6], per_on=per)\n",
    "    sim = DriveSimulator()\n",
    "    epsilons = []\n",
    "    avg_score = 0.0\n",
    "    avg_loss = 0.0\n",
    "\n",
    "    oe_a = 0.0\n",
    "    oe_b = 0.0\n",
    "    \n",
    "    for i in range(n_runs):\n",
    "        over = False\n",
    "        sim.reset(frame_rate=3000)\n",
    "\n",
    "        state = sim.get_sim_state()\n",
    "        while not over:\n",
    "            #print(state[0][0])\n",
    "            #print(agent.choose_action(state))\n",
    "            action, pred = agent.choose_action(state)\n",
    "            state_, stpRwd, sim_over = sim.step(action)\n",
    "            over = sim_over\n",
    "\n",
    "            agent.store_transition(state, action, stpRwd, state_, over, pred)\n",
    "            state = state_\n",
    "            \n",
    "            if pred > 5.0:\n",
    "                oe_a += 1.0\n",
    "            oe_b += 1.0\n",
    "\n",
    "        Loss = agent.learn(exps)\n",
    "        #overestimation detection\n",
    "\n",
    "\n",
    "        agent.epsilon = round(1.0 - (float(i)/float(n_runs)),3)\n",
    "        #scores.append(sim.agtRwd)\n",
    "    \n",
    "        avg_score += sim.agtRwd\n",
    "        avg_loss += Loss\n",
    "        if sim.episode_count % 100 == 0:\n",
    "            avg_score /= 100\n",
    "            avg_loss /= 100\n",
    "            print('Episode', sim.episode_count, ', average score(last 100 episodes):', avg_score, \\\n",
    "                'average loss:', avg_loss, 'wins:', sim.win_count, 'eps:', agent.epsilon)\n",
    "\n",
    "\n",
    "            print(f'DETECTED OVERESTIMATION: {oe_a/oe_b} ({oe_a}/{oe_b})')\n",
    "            oe_a = 0.0\n",
    "            oe_b = 0.0\n",
    "\n",
    "            train_scores[exps, i//100] = avg_score\n",
    "            train_losses[exps, i//100] = avg_loss\n",
    "            avg_score = 0.0\n",
    "            avg_loss = 0.0\n",
    "            epsilons.append(agent.epsilon)\n",
    "\n",
    "    agent.save_model(f'./models/q_20221224({exps})')\n",
    "np.savetxt(f'20221224_scores.csv', train_scores, delimiter=\",\")\n",
    "np.savetxt(f'20221224_losses.csv', train_losses, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_graph(date, label):\n",
    "    scores = np.genfromtxt(date + '_scores.csv', delimiter=',')\n",
    "    losses = np.genfromtxt(date + '_losses.csv', delimiter=',')\n",
    "\n",
    "    # Plot Score\n",
    "    plt.title(label + ' (score)')\n",
    "    for i in range(EXP_COUNT):\n",
    "        plt.plot(scores[i], 'b')\n",
    "        plt.plot(8.0 * np.ones_like(scores[i]), 'gray') #Score 상한선\n",
    "        plt.plot(-5.0 * np.ones_like(scores[i]), 'gray') #Score 하한선\n",
    "        plt.show()\n",
    "    #plt.savefig(date + '_score.png')\n",
    "    #plt.show()\n",
    "\n",
    "    for i in range(EXP_COUNT):\n",
    "        plt.title(label + ' (loss)')\n",
    "        #Plot Loss\n",
    "        plt.plot(losses[i], 'orange')\n",
    "        plt.plot(1.5 * np.ones_like(losses[i]), 'gray') #Loss 상한선\n",
    "        plt.plot(np.zeros_like(losses[i]), 'gray') #Loss 하한선\n",
    "        plt.show()\n",
    "    #plt.savefig(date + '_loss.png')\n",
    "    #plt.show()\n",
    "\n",
    "save_graph(date = '20221209', label = 'test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 밑에는 예전에 쓰던 코드. . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이전에 저장한 학습 데이터 불러오기\n",
    "train_scores_2 = np.genfromtxt('20221014_concat_train_scores.csv', delimiter=',')\n",
    "\n",
    "for exps in range(EXP_COUNT):\n",
    "    plt.plot(train_scores_1[exps], 'b')\n",
    "plt.plot(train_scores_1.mean(axis=0), 'r')\n",
    "plt.show()\n",
    "\n",
    "for exps in range(EXP_COUNT):\n",
    "    print(train_scores_2[exps])\n",
    "    plt.plot(train_scores_2[exps], 'b')\n",
    "plt.plot(train_scores_2.mean(axis=0), 'r')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_scores_2.mean(axis=0), 'r')\n",
    "plt.plot(train_scores_1.mean(axis=0), 'b')\n",
    "plt.savefig('compare_20221004_per')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 데이터 비교!!!!!\n",
    "scores_Random = np.genfromtxt('20221017_concat_train_scores.csv', delimiter=',')\n",
    "scores_Error_PER = np.genfromtxt('20221016_concat_train_scores.csv', delimiter=',')\n",
    "scores_Reward_PER = np.genfromtxt('20221014_concat_train_scores.csv', delimiter=',')\n",
    "\n",
    "plt.plot(scores_Random.mean(axis=0), 'k', label='Random')\n",
    "plt.plot(scores_Error_PER.mean(axis=0), 'b', label='TD-Error based')\n",
    "plt.plot(scores_Reward_PER.mean(axis=0), 'r', label='Reward based')\n",
    "plt.legend()\n",
    "plt.savefig(\"compare_sampling_methods_20221017.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_max = scores_Random.min(axis=0)\n",
    "score_min = scores_Random.max(axis=0)\n",
    "plt.fill_between(range(100), score_max, score_min, color = 'gray', alpha = 0.1)\n",
    "\n",
    "score_max = scores_Error_PER.min(axis=0)\n",
    "score_min = scores_Error_PER.max(axis=0)\n",
    "plt.fill_between(range(100), score_max, score_min, color = 'b', alpha = 0.1)\n",
    "\n",
    "score_max = scores_Reward_PER.min(axis=0)\n",
    "score_min = scores_Reward_PER.max(axis=0)\n",
    "plt.fill_between(range(100), score_max, score_min, color = 'r', alpha = 0.1)\n",
    "\n",
    "\n",
    "plt.plot(scores_Random.mean(axis=0), 'gray', label='Random')\n",
    "plt.plot(scores_Error_PER.mean(axis=0), 'b', label='TD-Error based')\n",
    "plt.plot(scores_Reward_PER.mean(axis=0), 'r', label='Reward based')\n",
    "\n",
    "plt.xlabel('Episodes/100')\n",
    "plt.ylabel('Average Reward (during last 100 episodes)')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"compare_sampling_methods_with_range_20221017.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_max = scores_Random.min(axis=0)\n",
    "score_min = scores_Random.max(axis=0)\n",
    "plt.fill_between(range(100), score_max, score_min, color = 'gray', alpha = 0.1)\n",
    "\n",
    "score_max = scores_Reward_PER.min(axis=0)\n",
    "score_min = scores_Reward_PER.max(axis=0)\n",
    "plt.fill_between(range(100), score_max, score_min, color = 'orange', alpha = 0.1)\n",
    "\n",
    "\n",
    "plt.plot(scores_Random.mean(axis=0), 'gray', label='Random')\n",
    "plt.plot(scores_Reward_PER.mean(axis=0), 'orange', label='Reward based')\n",
    "\n",
    "plt.xlabel('Episodes/100')\n",
    "plt.ylabel('Average Reward (during last 100 episodes)')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"compare_aw_with_range_20221017.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('20221017_concat_train_scores.csv', train_scores_1, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "f2ca063fdbe114e1b6e4d04529a071bcb4f5c073e5b3f4bc04898c7d4aae4031"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
