{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Network import *\n",
    "from DriveSim import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#시뮬레이션 학습 코드\n",
    "if __name__ == '__main__':\n",
    "    wins = 0\n",
    "    n_runs = 10000\n",
    "    agent = Agent(lr=0.003, gamma=0.99, n_actions=5, batch_size=64, epsilon=1.0, input_dims=[6])\n",
    "    sim = DriveSimulator()\n",
    "    train_scores = []\n",
    "    epsilons = []\n",
    "    avg_score = 0.0\n",
    "    for i in range(n_runs):\n",
    "        over = False\n",
    "        sim.reset(frame_rate=300)\n",
    "\n",
    "        state = sim.get_sim_state()\n",
    "        while not over:\n",
    "            action = agent.choose_action(state)\n",
    "            state_, stpRwd, sim_over = sim.step(action)\n",
    "            over = sim_over\n",
    "\n",
    "            agent.store_transition(state, action, stpRwd, state_, over)\n",
    "            state = state_\n",
    "\n",
    "        agent.learn()\n",
    "        agent.epsilon = 1.0 - (float(i)/float(n_runs))\n",
    "        #scores.append(sim.agtRwd)\n",
    "        \n",
    "        avg_score += sim.agtRwd\n",
    "        if sim.episode_count % 100 == 0:\n",
    "            print('Episode', sim.episode_count, ', average score(last 100 episodes):', avg_score/100, 'wins:', sim.win_count, 'eps:', agent.epsilon)\n",
    "            train_scores.append(avg_score/100)\n",
    "            epsilons.append(agent.epsilon)\n",
    "            avg_score = 0.0\n",
    "\n",
    "    agent.save_model('./models/q_20220926')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent.q_eval.Aw.kernal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 결과 테스트\n",
    "if __name__ == '__main__':\n",
    "    wins = 0\n",
    "    test_runs = 100\n",
    "\n",
    "    sim = DriveSimulator()\n",
    "    scores = []\n",
    "    epsilons = []\n",
    "    for i in range(test_runs):\n",
    "        over = False\n",
    "        sim.reset(frame_rate=30)\n",
    "\n",
    "        state = sim.get_sim_state()\n",
    "        while not over:\n",
    "            action = agent.choose_action(state)\n",
    "            state_, stpRwd, sim_over = sim.step(action)\n",
    "            over = sim_over\n",
    "            state = state_\n",
    "\n",
    "        scores.append(sim.agtRwd)\n",
    "        print('Episode', sim.episode_count, ', score:', sim.agtRwd, 'wins:', sim.win_count, 't:', sim.t)\n",
    "    x = [i + 1 for i in range(test_runs)]\n",
    "    plt.plot(x, scores)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습된 정책의 action 분포 측정\n",
    "if __name__ == '__main__':\n",
    "    test_agent = Agent(lr=0.0005, gamma=0.99, n_actions=5, batch_size=64, epsilon=0, input_dims=[6])\n",
    "    test_agent.load_model('./models/q_20220926')\n",
    "    wins = 0\n",
    "    test_runs = 100\n",
    "\n",
    "    sim = DriveSimulator()\n",
    "    scores = []\n",
    "    epsilons = []\n",
    "    stats = [0,0,0,0,0]\n",
    "    for i in range(test_runs):\n",
    "        over = False\n",
    "        sim.reset(frame_rate=30)\n",
    "\n",
    "        state = sim.get_sim_state()\n",
    "        while not over:\n",
    "            action = test_agent.choose_action(state)\n",
    "            stats[action] += 1\n",
    "            state_, stpRwd, sim_over = sim.step(action)\n",
    "            over = sim_over\n",
    "            state = state_\n",
    "\n",
    "        scores.append(sim.agtRwd)\n",
    "        print('Episode', sim.episode_count, ', score:', sim.agtRwd, 'wins:', sim.win_count, 't:', sim.t)\n",
    "    x = [i + 1 for i in range(test_runs)]\n",
    "    plt.plot(x, scores / np.sum(scores,axis=0))\n",
    "    plt.show()\n",
    "\n",
    "    plt.bar(['stay','accel', 'decel', 'left', 'right'], stats)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats)\n",
    "\n",
    "#0.017 0.728 0.0026 0.119 0.134\n",
    "#0.0701 0.0611 0.0065 0.1748 0.1370"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "f2ca063fdbe114e1b6e4d04529a071bcb4f5c073e5b3f4bc04898c7d4aae4031"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
